---
layout: post
title: About the AI hype (transformers)
categories: AI
---

As the black-box algorithm, neural networks, taking over image and natural language processing, the hype of near-human level AI is unprecedented. Driveless car, human-level chat robot, shows suddenly the future of human hitory is approaching at a phenomenal speed. All the old school modeling are dead. Is it the end of mathematical and statistical modeling? Is it the end of human intellegence? 
As I study more and more about neural networks, especially [transformers](https://github.com/juntaoduan/Time-Series-Analysis_Classical_and_NeuralNet), it becomes clear to me that the hype is hoping too much 'unrealistic fantasy'. Here are some of the reasons I learned from an experiment.

## Language can be memorized but time series can not!
* From this experiment, we can confirm that Neural network in general does not outperform the classical wisdom of decoposing time series. In the following experiment, one consistently see Arima outperform Neural networks. So what is going on?
* 1. Why does deep learning fail to help us? There are several reasons.
    * The bottom line is learning language is very different from learning to predict time series. Time series data come naturally from dynamics of a certain real world system and it is usually continuous and volatile which made it is hard to capture the pattern completely. On the other hand, language can be learned completely and characterized 100% by human. With minimal degradation, we encoded language with letters and symbols so we can communicate long range both in time and space. Due to the very large capacity of a transformer-type neural network model, it can simply memorize this encoding and make 'human-natural' predications of language. While time series does not have the luxuary of 'memoriz-ability' and usualy exhibits chaotic behavior.
    * Continuous vs discrete. Language naturally is discrete and can be easily embeded into a low dimensional space. It is possible to memorize the seperation of discrete signals. On the other hand, continous time series signal is more adapted to a decomposition type modeling such as Fourier and wavelet transformations.
* 2. Is calssical statistical method the only way to model time series?
    * The answer is False. When dataset is large and complex, classical method is too simple and naive which losses much of the details in the data. Then there is an alternative solution is to handcraft features and use tree-type structure discovering models, for example Gradient Boosting Tree.


## Reference: 
[1.](https://github.com/juntaoduan/Time-Series-Analysis_Classical_and_NeuralNet)

----
****
